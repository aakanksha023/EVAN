{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "\n",
    "Author: Jasmine Qin  \n",
    "Date: 2020-06-29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Shapely\n",
    "from shapely.ops import nearest_points\n",
    "from shapely.geometry import Point, Polygon\n",
    "import shapely.speedups\n",
    "\n",
    "# For nearby business\n",
    "from functools import partial\n",
    "import pyproj\n",
    "from shapely.ops import transform\n",
    "proj_wgs84 = pyproj.Proj('+proj=longlat +datum=WGS84')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "shapely.speedups.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train = pd.read_csv('../../data/processed/04_combined_train.csv',\n",
    "                    low_memory=False)\n",
    "combined_validation = pd.read_csv('../../data/processed/04_combined_validate.csv',\n",
    "                         low_memory=False)\n",
    "combined_test = pd.read_csv('../../data/processed/04_combined_test.csv',\n",
    "                         low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_licence = pd.concat([combined_train, combined_validation, combined_test])\n",
    "all_licence = all_licence[~(all_licence.FOLDERYEAR == 2020)]\n",
    "all_licence = all_licence[all_licence.Geom.notnull()]\n",
    "all_licence = all_licence[['LicenceRSN', 'FOLDERYEAR', 'BusinessType', 'Geom']]\n",
    "\n",
    "all_licence['lat'] = all_licence.Geom.apply(lambda p: json.loads(p)['coordinates'][1])\n",
    "all_licence['lon'] = all_licence.Geom.apply(lambda p: json.loads(p)['coordinates'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(453989, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_licence.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearby business - train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return buffer region\n",
    "def buffer_polygon(lat, lon, m):\n",
    "\n",
    "    aeqd_proj = '+proj=aeqd +lat_0={lat} +lon_0={lon} +x_0=0 +y_0=0'\n",
    "    project = partial(\n",
    "        pyproj.transform,\n",
    "        pyproj.Proj(aeqd_proj.format(lat=lat, lon=lon)),\n",
    "        proj_wgs84)\n",
    "    \n",
    "    buffer = transform(project, Point(0, 0).buffer(m)).exterior.coords[:]\n",
    "    \n",
    "    return Polygon([[p[0], p[1]] for p in buffer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def business_lookup(df):\n",
    "    business_lookup = defaultdict(dict)\n",
    "    for y in df.FOLDERYEAR.unique():\n",
    "        for i in df.BusinessType.unique():\n",
    "            df_y_i = df[(df.FOLDERYEAR == y) & (df.BusinessType == i)]\n",
    "            points = df_y_i.point\n",
    "            for index, row in df_y_i.iterrows():\n",
    "                business_lookup[y][row.business_id] = np.asarray(\n",
    "                    [row.polygon.contains(i) for i in points]).sum()-1\n",
    "\n",
    "    business_lookup = {(outerKey, innerKey): values for outerKey, innerDict in business_lookup.items()\n",
    "                       for innerKey, values in innerDict.items()}\n",
    "    business_lookup = pd.DataFrame(business_lookup, index=[\n",
    "        'nearest_business_count']).T.reset_index().rename(\n",
    "        columns={'level_0': 'FOLDERYEAR',\n",
    "                 'level_1': 'business_id'})\n",
    "\n",
    "    df = df.merge(\n",
    "        business_lookup,\n",
    "        how='left',\n",
    "        left_on=['FOLDERYEAR', 'business_id'],\n",
    "        right_on=['FOLDERYEAR', 'business_id'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_all_years = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jq/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jq/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "df_1997 = all_licence[all_licence.FOLDERYEAR == 1997]\n",
    "df_1997['point'] = df_1997.apply(lambda p: Point(p.lon, p.lat), axis=1)\n",
    "df_1997['polygon'] = df_1997.apply(\n",
    "    lambda p: buffer_polygon(p.lat, p.lon, 200), axis=1)\n",
    "\n",
    "for i in df_1997.BusinessType.unique():\n",
    "    df_i = df_1997[df_1997.BusinessType == i]\n",
    "    points = df_i.point\n",
    "\n",
    "    for index, row in df_i.iterrows():\n",
    "        dict_all_years[row.LicenceRSN] = np.asarray(\n",
    "            [row.polygon.contains(p) for p in points]).sum()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jq/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jq/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "df_1998 = all_licence[all_licence.FOLDERYEAR == 1998]\n",
    "df_1998['point'] = df_1998.apply(lambda p: Point(p.lon, p.lat), axis=1)\n",
    "df_1998['polygon'] = df_1998.apply(\n",
    "    lambda p: buffer_polygon(p.lat, p.lon, 200), axis=1)\n",
    "\n",
    "for i in df_1998.BusinessType.unique():\n",
    "    df_i = df_1998[df_1998.BusinessType == i]\n",
    "    points = df_i.point\n",
    "\n",
    "    for index, row in df_i.iterrows():\n",
    "        dict_all_years[row.LicenceRSN] = np.asarray(\n",
    "            [row.polygon.contains(p) for p in points]).sum()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jq/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jq/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "df_1999 = all_licence[all_licence.FOLDERYEAR == 1999]\n",
    "df_1999['point'] = df_1999.apply(lambda p: Point(p.lon, p.lat), axis=1)\n",
    "df_1999['polygon'] = df_1999.apply(\n",
    "    lambda p: buffer_polygon(p.lat, p.lon, 200), axis=1)\n",
    "\n",
    "for i in df_1999.BusinessType.unique():\n",
    "    df_i = df_1999[df_1999.BusinessType == i]\n",
    "    points = df_i.point\n",
    "\n",
    "    for index, row in df_i.iterrows():\n",
    "        dict_all_years[row.LicenceRSN] = np.asarray(\n",
    "            [row.polygon.contains(p) for p in points]).sum()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jq/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jq/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "df_2000 = all_licence[all_licence.FOLDERYEAR == 2000]\n",
    "df_2000['point'] = df_2000.apply(lambda p: Point(p.lon, p.lat), axis=1)\n",
    "df_2000['polygon'] = df_2000.apply(\n",
    "    lambda p: buffer_polygon(p.lat, p.lon, 200), axis=1)\n",
    "\n",
    "for i in df_2000.BusinessType.unique():\n",
    "    df_i = df_2000[df_2000.BusinessType == i]\n",
    "    points = df_i.point\n",
    "\n",
    "    for index, row in df_i.iterrows():\n",
    "        dict_all_years[row.LicenceRSN] = np.asarray(\n",
    "            [row.polygon.contains(p) for p in points]).sum()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63725\n",
      "(63736, 8)\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_all_years))\n",
    "print(pd.concat([df_1997, df_1998, df_1999, df_2000]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2001 = all_licence[all_licence.FOLDERYEAR == 2001]\n",
    "df_2001['point'] = df_2001.apply(lambda p: Point(p.lon, p.lat), axis=1)\n",
    "df_2001['polygon'] = df_2001.apply(\n",
    "    lambda p: buffer_polygon(p.lat, p.lon, 200), axis=1)\n",
    "\n",
    "for i in df_2001.BusinessType.unique():\n",
    "    df_i = df_2001[df_2001.BusinessType == i]\n",
    "    points = df_i.point\n",
    "\n",
    "    for index, row in df_i.iterrows():\n",
    "        dict_all_years[row.LicenceRSN] = np.asarray(\n",
    "            [row.polygon.contains(p) for p in points]).sum()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2002 = all_licence[all_licence.FOLDERYEAR == 2002]\n",
    "df_2002['point'] = df_2002.apply(lambda p: Point(p.lon, p.lat), axis=1)\n",
    "df_2002['polygon'] = df_2002.apply(\n",
    "    lambda p: buffer_polygon(p.lat, p.lon, 200), axis=1)\n",
    "\n",
    "for i in df_2002.BusinessType.unique():\n",
    "    df_i = df_2002[df_2002.BusinessType == i]\n",
    "    points = df_i.point\n",
    "\n",
    "    for index, row in df_i.iterrows():\n",
    "        dict_all_years[row.LicenceRSN] = np.asarray(\n",
    "            [row.polygon.contains(p) for p in points]).sum()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2003 = all_licence[all_licence.FOLDERYEAR == 2003]\n",
    "df_2003['point'] = df_2003.apply(lambda p: Point(p.lon, p.lat), axis=1)\n",
    "df_2003['polygon'] = df_2003.apply(\n",
    "    lambda p: buffer_polygon(p.lat, p.lon, 200), axis=1)\n",
    "\n",
    "for i in df_2003.BusinessType.unique():\n",
    "    df_i = df_2003[df_2003.BusinessType == i]\n",
    "    points = df_i.point\n",
    "\n",
    "    for index, row in df_i.iterrows():\n",
    "        dict_all_years[row.LicenceRSN] = np.asarray(\n",
    "            [row.polygon.contains(p) for p in points]).sum()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120253\n",
      "(120265, 8)\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_all_years))\n",
    "print(pd.concat([df_1997, df_1998, df_1999, df_2000, df_2001, df_2002, df_2003]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2004 = all_licence[all_licence.FOLDERYEAR == 2004]\n",
    "df_2004['point'] = df_2004.apply(lambda p: Point(p.lon, p.lat), axis=1)\n",
    "df_2004['polygon'] = df_2004.apply(\n",
    "    lambda p: buffer_polygon(p.lat, p.lon, 200), axis=1)\n",
    "\n",
    "for i in df_2004.BusinessType.unique():\n",
    "    df_i = df_2004[df_2004.BusinessType == i]\n",
    "    points = df_i.point\n",
    "\n",
    "    for index, row in df_i.iterrows():\n",
    "        dict_all_years[row.LicenceRSN] = np.asarray(\n",
    "            [row.polygon.contains(p) for p in points]).sum()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2005 = all_licence[all_licence.FOLDERYEAR == 2005]\n",
    "df_2005['point'] = df_2005.apply(lambda p: Point(p.lon, p.lat), axis=1)\n",
    "df_2005['polygon'] = df_2005.apply(\n",
    "    lambda p: buffer_polygon(p.lat, p.lon, 200), axis=1)\n",
    "\n",
    "for i in df_2005.BusinessType.unique():\n",
    "    df_i = df_2005[df_2005.BusinessType == i]\n",
    "    points = df_i.point\n",
    "\n",
    "    for index, row in df_i.iterrows():\n",
    "        dict_all_years[row.LicenceRSN] = np.asarray(\n",
    "            [row.polygon.contains(p) for p in points]).sum()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2006 = all_licence[all_licence.FOLDERYEAR == 2006]\n",
    "df_2006['point'] = df_2006.apply(lambda p: Point(p.lon, p.lat), axis=1)\n",
    "df_2006['polygon'] = df_2006.apply(\n",
    "    lambda p: buffer_polygon(p.lat, p.lon, 200), axis=1)\n",
    "\n",
    "for i in df_2006.BusinessType.unique():\n",
    "    df_i = df_2006[df_2006.BusinessType == i]\n",
    "    points = df_i.point\n",
    "\n",
    "    for index, row in df_i.iterrows():\n",
    "        dict_all_years[row.LicenceRSN] = np.asarray(\n",
    "            [row.polygon.contains(p) for p in points]).sum()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176950\n",
      "(176963, 8)\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_all_years))\n",
    "print(pd.concat([df_1997, df_1998, df_1999, df_2000, \n",
    "                 df_2001, df_2002, df_2003, df_2004,\n",
    "                 df_2005, df_2006]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2007 = all_licence[all_licence.FOLDERYEAR == 2007]\n",
    "df_2007['point'] = df_2007.apply(lambda p: Point(p.lon, p.lat), axis=1)\n",
    "df_2007['polygon'] = df_2007.apply(\n",
    "    lambda p: buffer_polygon(p.lat, p.lon, 200), axis=1)\n",
    "\n",
    "for i in df_2007.BusinessType.unique():\n",
    "    df_i = df_2007[df_2007.BusinessType == i]\n",
    "    points = df_i.point\n",
    "\n",
    "    for index, row in df_i.iterrows():\n",
    "        dict_all_years[row.LicenceRSN] = np.asarray(\n",
    "            [row.polygon.contains(p) for p in points]).sum()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2008 = all_licence[all_licence.FOLDERYEAR == 2008]\n",
    "df_2008['point'] = df_2008.apply(lambda p: Point(p.lon, p.lat), axis=1)\n",
    "df_2008['polygon'] = df_2008.apply(\n",
    "    lambda p: buffer_polygon(p.lat, p.lon, 200), axis=1)\n",
    "\n",
    "for i in df_2008.BusinessType.unique():\n",
    "    df_i = df_2008[df_2008.BusinessType == i]\n",
    "    points = df_i.point\n",
    "\n",
    "    for index, row in df_i.iterrows():\n",
    "        dict_all_years[row.LicenceRSN] = np.asarray(\n",
    "            [row.polygon.contains(p) for p in points]).sum()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2009 = all_licence[all_licence.FOLDERYEAR == 2009]\n",
    "df_2009['point'] = df_2009.apply(lambda p: Point(p.lon, p.lat), axis=1)\n",
    "df_2009['polygon'] = df_2009.apply(\n",
    "    lambda p: buffer_polygon(p.lat, p.lon, 200), axis=1)\n",
    "\n",
    "for i in df_2009.BusinessType.unique():\n",
    "    df_i = df_2009[df_2009.BusinessType == i]\n",
    "    points = df_i.point\n",
    "\n",
    "    for index, row in df_i.iterrows():\n",
    "        dict_all_years[row.LicenceRSN] = np.asarray(\n",
    "            [row.polygon.contains(p) for p in points]).sum()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236579\n",
      "(236593, 8)\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_all_years))\n",
    "print(pd.concat([df_1997, df_1998, df_1999, df_2000, \n",
    "                 df_2001, df_2002, df_2003, df_2004,\n",
    "                 df_2005, df_2006, df_2007, df_2008,\n",
    "                 df_2009]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2010 = all_licence[all_licence.FOLDERYEAR == 2010]\n",
    "df_2010['point'] = df_2010.apply(lambda p: Point(p.lon, p.lat), axis=1)\n",
    "df_2010['polygon'] = df_2010.apply(\n",
    "    lambda p: buffer_polygon(p.lat, p.lon, 200), axis=1)\n",
    "\n",
    "for i in df_2010.BusinessType.unique():\n",
    "    df_i = df_2010[df_2010.BusinessType == i]\n",
    "    points = df_i.point\n",
    "\n",
    "    for index, row in df_i.iterrows():\n",
    "        dict_all_years[row.LicenceRSN] = np.asarray(\n",
    "            [row.polygon.contains(p) for p in points]).sum()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2011 = all_licence[all_licence.FOLDERYEAR == 2011]\n",
    "df_2011['point'] = df_2011.apply(lambda p: Point(p.lon, p.lat), axis=1)\n",
    "df_2011['polygon'] = df_2011.apply(\n",
    "    lambda p: buffer_polygon(p.lat, p.lon, 200), axis=1)\n",
    "\n",
    "for i in df_2011.BusinessType.unique():\n",
    "    df_i = df_2011[df_2011.BusinessType == i]\n",
    "    points = df_i.point\n",
    "\n",
    "    for index, row in df_i.iterrows():\n",
    "        dict_all_years[row.LicenceRSN] = np.asarray(\n",
    "            [row.polygon.contains(p) for p in points]).sum()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2012 = all_licence[all_licence.FOLDERYEAR == 2012]\n",
    "df_2012['point'] = df_2012.apply(lambda p: Point(p.lon, p.lat), axis=1)\n",
    "df_2012['polygon'] = df_2012.apply(\n",
    "    lambda p: buffer_polygon(p.lat, p.lon, 200), axis=1)\n",
    "\n",
    "for i in df_2012.BusinessType.unique():\n",
    "    df_i = df_2012[df_2012.BusinessType == i]\n",
    "    points = df_i.point\n",
    "\n",
    "    for index, row in df_i.iterrows():\n",
    "        dict_all_years[row.LicenceRSN] = np.asarray(\n",
    "            [row.polygon.contains(p) for p in points]).sum()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299501\n",
      "(299515, 8)\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_all_years))\n",
    "print(pd.concat([df_1997, df_1998, df_1999, df_2000, \n",
    "                 df_2001, df_2002, df_2003, df_2004,\n",
    "                 df_2005, df_2006, df_2007, df_2008,\n",
    "                 df_2009, df_2010, df_2011, df_2012]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2013 = all_licence[all_licence.FOLDERYEAR == 2013]\n",
    "df_2013['point'] = df_2013.apply(lambda p: Point(p.lon, p.lat), axis=1)\n",
    "df_2013['polygon'] = df_2013.apply(\n",
    "    lambda p: buffer_polygon(p.lat, p.lon, 200), axis=1)\n",
    "\n",
    "for i in df_2013.BusinessType.unique():\n",
    "    df_i = df_2013[df_2013.BusinessType == i]\n",
    "    points = df_i.point\n",
    "\n",
    "    for index, row in df_i.iterrows():\n",
    "        dict_all_years[row.LicenceRSN] = np.asarray(\n",
    "            [row.polygon.contains(p) for p in points]).sum()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2014 = all_licence[all_licence.FOLDERYEAR == 2014]\n",
    "df_2014['point'] = df_2014.apply(lambda p: Point(p.lon, p.lat), axis=1)\n",
    "df_2014['polygon'] = df_2014.apply(\n",
    "    lambda p: buffer_polygon(p.lat, p.lon, 200), axis=1)\n",
    "\n",
    "for i in df_2014.BusinessType.unique():\n",
    "    df_i = df_2014[df_2014.BusinessType == i]\n",
    "    points = df_i.point\n",
    "\n",
    "    for index, row in df_i.iterrows():\n",
    "        dict_all_years[row.LicenceRSN] = np.asarray(\n",
    "            [row.polygon.contains(p) for p in points]).sum()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015 = all_licence[all_licence.FOLDERYEAR == 2015]\n",
    "df_2015['point'] = df_2015.apply(lambda p: Point(p.lon, p.lat), axis=1)\n",
    "df_2015['polygon'] = df_2015.apply(\n",
    "    lambda p: buffer_polygon(p.lat, p.lon, 200), axis=1)\n",
    "\n",
    "for i in df_2015.BusinessType.unique():\n",
    "    df_i = df_2015[df_2015.BusinessType == i]\n",
    "    points = df_i.point\n",
    "\n",
    "    for index, row in df_i.iterrows():\n",
    "        dict_all_years[row.LicenceRSN] = np.asarray(\n",
    "            [row.polygon.contains(p) for p in points]).sum()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = all_licence[all_licence.FOLDERYEAR == 2016]\n",
    "df_2016['point'] = df_2016.apply(lambda p: Point(p.lon, p.lat), axis=1)\n",
    "df_2016['polygon'] = df_2016.apply(\n",
    "    lambda p: buffer_polygon(p.lat, p.lon, 200), axis=1)\n",
    "\n",
    "for i in df_2016.BusinessType.unique():\n",
    "    df_i = df_2016[df_2016.BusinessType == i]\n",
    "    points = df_i.point\n",
    "\n",
    "    for index, row in df_i.iterrows():\n",
    "        dict_all_years[row.LicenceRSN] = np.asarray(\n",
    "            [row.polygon.contains(p) for p in points]).sum()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017 = all_licence[all_licence.FOLDERYEAR == 2017]\n",
    "df_2017['point'] = df_2017.apply(lambda p: Point(p.lon, p.lat), axis=1)\n",
    "df_2017['polygon'] = df_2017.apply(\n",
    "    lambda p: buffer_polygon(p.lat, p.lon, 200), axis=1)\n",
    "\n",
    "for i in df_2017.BusinessType.unique():\n",
    "    df_i = df_2017[df_2017.BusinessType == i]\n",
    "    points = df_i.point\n",
    "\n",
    "    for index, row in df_i.iterrows():\n",
    "        dict_all_years[row.LicenceRSN] = np.asarray(\n",
    "            [row.polygon.contains(p) for p in points]).sum()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018 = all_licence[all_licence.FOLDERYEAR == 2018]\n",
    "df_2018['point'] = df_2018.apply(lambda p: Point(p.lon, p.lat), axis=1)\n",
    "df_2018['polygon'] = df_2018.apply(\n",
    "    lambda p: buffer_polygon(p.lat, p.lon, 200), axis=1)\n",
    "\n",
    "for i in df_2018.BusinessType.unique():\n",
    "    df_i = df_2018[df_2018.BusinessType == i]\n",
    "    points = df_i.point\n",
    "\n",
    "    for index, row in df_i.iterrows():\n",
    "        dict_all_years[row.LicenceRSN] = np.asarray(\n",
    "            [row.polygon.contains(p) for p in points]).sum()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019 = all_licence[all_licence.FOLDERYEAR == 2019]\n",
    "df_2019['point'] = df_2019.apply(lambda p: Point(p.lon, p.lat), axis=1)\n",
    "df_2019['polygon'] = df_2019.apply(\n",
    "    lambda p: buffer_polygon(p.lat, p.lon, 200), axis=1)\n",
    "\n",
    "for i in df_2019.BusinessType.unique():\n",
    "    df_i = df_2019[df_2019.BusinessType == i]\n",
    "    points = df_i.point\n",
    "\n",
    "    for index, row in df_i.iterrows():\n",
    "        dict_all_years[row.LicenceRSN] = np.asarray(\n",
    "            [row.polygon.contains(p) for p in points]).sum()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453973\n",
      "(453989, 8)\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_all_years))\n",
    "print(pd.concat([df_1997, df_1998, df_1999, df_2000, \n",
    "                 df_2001, df_2002, df_2003, df_2004,\n",
    "                 df_2005, df_2006, df_2007, df_2008,\n",
    "                 df_2009, df_2010, df_2011, df_2012,\n",
    "                 df_2013, df_2014, df_2015, df_2016,\n",
    "                 df_2017, df_2018, df_2019]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dict_all_years, index=[\n",
    "    'nearest_business_count']).T.reset_index().rename(\n",
    "    columns={'index': 'LicenceRSN'}).to_csv(\"nearby_business.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=df.polygon.values[0]\n",
    "x=[i[0] for i in p]\n",
    "y=[i[1] for i in p]\n",
    "x.append(json.loads(df.Geom.values[0])['coordinates'][0])\n",
    "y.append(json.loads(df.Geom.values[0])['coordinates'][1])\n",
    "new_df=pd.DataFrame({\"x\":x, \"y\":y})\n",
    "\n",
    "# Basics\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.offline import iplot\n",
    "\n",
    "mapbox_access_token = \"pk.eyJ1IjoiamFzbWluZXF5aiIsImEiOiJja2Fyc2toN2Ewb3FxMnJsZzhuN3N3azk2In0.SJcixuEa_agNUDz7fFYDEg\"\n",
    "px.set_mapbox_access_token(mapbox_access_token)\n",
    "\n",
    "scatter = px.scatter_mapbox(new_df,\n",
    "                            lat=\"y\",\n",
    "                            lon=\"x\")\n",
    "\n",
    "scatter.update_layout(height=800,\n",
    "                      width=1000,\n",
    "                      mapbox_center={\"lat\": 49.250, \"lon\": -123.121})\n",
    "\n",
    "scatter.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
